{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPO Pre-Analysis: Model Training & Scoring\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Loading historical IPO data\n",
    "2. Feature engineering from S-1 filings and market data\n",
    "3. Training a classification model\n",
    "4. Scoring upcoming IPOs for trading\n",
    "\n",
    "**Workflow:**\n",
    "- Run this notebook weekly to score upcoming IPOs\n",
    "- Export scores to CSV for the trading algorithm\n",
    "- Retrain model quarterly with new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QuantConnect imports\n",
    "qb = QuantBook()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML imports\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import joblib\n",
    "\n",
    "# Local modules\n",
    "from ipoanalyzer import IPOFeatureExtractor, IPOScorer\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Historical IPO Data\n",
    "\n",
    "**Data Collection Strategy:**\n",
    "\n",
    "You need to build a historical dataset of IPOs from 2015-2024. Sources:\n",
    "1. **IPO Calendar:** Renaissance Capital, Nasdaq, IPOScoop\n",
    "2. **S-1 Filings:** SEC EDGAR API\n",
    "3. **Price Data:** Yahoo Finance, QuantConnect\n",
    "4. **News Sentiment:** Google News, AlphaSense\n",
    "\n",
    "**CSV Format:**\n",
    "```\n",
    "ticker,listing_date,offer_price,first_day_close,return_30d,revenue,revenue_growth,...\n",
    "ABNB,2020-12-10,68.00,144.71,0.35,4805000000,0.76,...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load historical IPO data\n",
    "# For demo purposes, we'll create synthetic data\n",
    "# In production, replace with real historical data\n",
    "\n",
    "def create_synthetic_ipo_data(n_samples=500):\n",
    "    \"\"\"\n",
    "    Create synthetic IPO data for demonstration.\n",
    "    Replace this with real historical data.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    data = {\n",
    "        # Target variable: Did IPO return >10% in first 30 days?\n",
    "        'success': np.random.binomial(1, 0.55, n_samples),\n",
    "        \n",
    "        # Fundamental features\n",
    "        'revenue_mm': np.random.lognormal(6, 1.5, n_samples),\n",
    "        'revenue_growth_yoy': np.random.normal(40, 30, n_samples),\n",
    "        'gross_margin': np.random.normal(50, 20, n_samples).clip(0, 90),\n",
    "        'operating_margin': np.random.normal(5, 25, n_samples).clip(-50, 40),\n",
    "        'is_profitable': np.random.binomial(1, 0.35, n_samples),\n",
    "        'cash_mm': np.random.lognormal(5, 1.2, n_samples),\n",
    "        'debt_to_equity': np.random.exponential(0.5, n_samples).clip(0, 3),\n",
    "        'customer_concentration': np.random.beta(2, 5, n_samples) * 100,\n",
    "        'employees': np.random.lognormal(6, 1.5, n_samples),\n",
    "        'company_age': np.random.exponential(8, n_samples).clip(1, 50),\n",
    "        \n",
    "        # Deal characteristics\n",
    "        'price_vs_range': np.random.normal(5, 15, n_samples),\n",
    "        'float_pct': np.random.normal(20, 10, n_samples).clip(5, 50),\n",
    "        'price_to_sales': np.random.lognormal(2, 1, n_samples).clip(0.5, 50),\n",
    "        'underwriter_tier': np.random.binomial(1, 0.45, n_samples),\n",
    "        'lockup_days': np.random.choice([90, 180, 365], n_samples),\n",
    "        'greenshoe_pct': np.random.normal(15, 3, n_samples).clip(0, 20),\n",
    "        'proceeds_for_growth': np.random.beta(3, 2, n_samples),\n",
    "        'subscription_level': np.random.normal(0, 1, n_samples),\n",
    "        \n",
    "        # Market conditions\n",
    "        'vix': np.random.gamma(2, 8, n_samples).clip(10, 60),\n",
    "        'spy_return_30d': np.random.normal(2, 5, n_samples),\n",
    "        'sector_return_30d': np.random.normal(2.5, 7, n_samples),\n",
    "        'ipo_market_temp': np.random.normal(8, 15, n_samples),\n",
    "        'ipos_same_week': np.random.poisson(2, n_samples).clip(0, 10),\n",
    "        \n",
    "        # Sentiment\n",
    "        'finbert_score': np.random.normal(0.2, 0.3, n_samples).clip(-1, 1),\n",
    "        'news_volume': np.random.poisson(15, n_samples),\n",
    "        'sentiment_velocity': np.random.normal(0, 0.5, n_samples),\n",
    "        'social_buzz': np.random.gamma(2, 10, n_samples).clip(0, 100),\n",
    "        'google_trends': np.random.gamma(2, 15, n_samples).clip(0, 100),\n",
    "    }\n",
    "    \n",
    "    # Make some features correlated with success\n",
    "    success_mask = data['success'] == 1\n",
    "    data['revenue_growth_yoy'][success_mask] += 20\n",
    "    data['price_vs_range'][success_mask] += 8\n",
    "    data['finbert_score'][success_mask] += 0.2\n",
    "    data['underwriter_tier'][success_mask] = np.random.binomial(1, 0.65, success_mask.sum())\n",
    "    data['vix'][success_mask] -= 5\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load data\n",
    "# df = pd.read_csv('data/historical_ipos.csv')  # Use this in production\n",
    "df = create_synthetic_ipo_data(n_samples=500)\n",
    "\n",
    "print(f\"Loaded {len(df)} historical IPOs\")\n",
    "print(f\"Success rate: {df['success'].mean():.1%}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature distributions\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "key_features = ['revenue_growth_yoy', 'gross_margin', 'price_vs_range', \n",
    "                'underwriter_tier', 'vix', 'finbert_score', \n",
    "                'float_pct', 'price_to_sales', 'sentiment_velocity']\n",
    "\n",
    "for i, feature in enumerate(key_features):\n",
    "    for success in [0, 1]:\n",
    "        subset = df[df['success'] == success][feature]\n",
    "        axes[i].hist(subset, alpha=0.6, label=f'Success={success}', bins=30)\n",
    "    axes[i].set_title(feature)\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFeature correlations with success:\")\n",
    "correlations = df.corr()['success'].sort_values(ascending=False)\n",
    "print(correlations[1:11])  # Top 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "feature_names = [col for col in df.columns if col != 'success']\n",
    "X = df[feature_names]\n",
    "y = df['success']\n",
    "\n",
    "# Split data (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Train success rate: {y_train.mean():.1%}\")\n",
    "print(f\"Test success rate: {y_test.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LightGBM classifier\n",
    "model = LGBMClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    num_leaves=31,\n",
    "    min_child_samples=20,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Cross-validation score\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"\\nCross-validation AUC: {cv_scores.mean():.3f} (+/- {cv_scores.std():.3f})\")\n",
    "\n",
    "print(\"\\nModel trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Fail', 'Success']))\n",
    "\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"\\nROC AUC Score: {auc:.3f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Fail', 'Success'], \n",
    "            yticklabels=['Fail', 'Success'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importance['feature'][:15], feature_importance['importance'][:15])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 15 Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Analyze Trading Strategy Performance\n",
    "\n",
    "Simulate trading based on model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate returns based on different confidence thresholds\n",
    "thresholds = [0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80]\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Only trade when model confidence > threshold\n",
    "    trades = y_pred_proba > threshold\n",
    "    \n",
    "    if trades.sum() == 0:\n",
    "        continue\n",
    "    \n",
    "    # Calculate metrics\n",
    "    n_trades = trades.sum()\n",
    "    accuracy = (y_test[trades] == y_pred[trades]).mean()\n",
    "    \n",
    "    # Simulate returns (assume +25% on success, -15% on failure)\n",
    "    returns = y_test[trades] * 0.25 + (1 - y_test[trades]) * -0.15\n",
    "    avg_return = returns.mean()\n",
    "    sharpe = returns.mean() / returns.std() * np.sqrt(12)  # Annualized\n",
    "    \n",
    "    results.append({\n",
    "        'threshold': threshold,\n",
    "        'n_trades': n_trades,\n",
    "        'accuracy': accuracy,\n",
    "        'avg_return': avg_return,\n",
    "        'sharpe': sharpe\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Strategy Performance by Confidence Threshold:\\n\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(results_df['threshold'], results_df['n_trades'], marker='o')\n",
    "axes[0].set_xlabel('Confidence Threshold')\n",
    "axes[0].set_ylabel('Number of Trades')\n",
    "axes[0].set_title('Trade Frequency')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(results_df['threshold'], results_df['accuracy'], marker='o', color='green')\n",
    "axes[1].set_xlabel('Confidence Threshold')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Prediction Accuracy')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(results_df['threshold'], results_df['avg_return'] * 100, marker='o', color='blue')\n",
    "axes[2].set_xlabel('Confidence Threshold')\n",
    "axes[2].set_ylabel('Average Return (%)')\n",
    "axes[2].set_title('Expected Return per Trade')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n** Recommended Threshold: 0.70 **\")\n",
    "print(f\"This balances accuracy ({results_df[results_df['threshold']==0.70]['accuracy'].values[0]:.1%}) with trade frequency.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Save Model for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to Object Store\n",
    "model_bytes = joblib.dumps(model)\n",
    "qb.object_store.save_bytes('ipo_classifier_model', model_bytes)\n",
    "\n",
    "# Also save feature names\n",
    "feature_data = {'feature_names': feature_names}\n",
    "import json\n",
    "qb.object_store.save('ipo_feature_names', json.dumps(feature_data))\n",
    "\n",
    "print(\"Model saved to Object Store!\")\n",
    "print(f\"Model file: ipo_classifier_model\")\n",
    "print(f\"Features: {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Score Upcoming IPOs\n",
    "\n",
    "Use this section weekly to score upcoming IPOs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Score a new IPO\n",
    "# In production, you would:\n",
    "# 1. Get IPO calendar for next 30 days\n",
    "# 2. For each IPO, extract features from S-1 filing\n",
    "# 3. Score with model\n",
    "# 4. Export to CSV\n",
    "\n",
    "def score_new_ipo(ipo_info, model, feature_names):\n",
    "    \"\"\"\n",
    "    Score a new IPO.\n",
    "    \n",
    "    Args:\n",
    "        ipo_info: Dictionary with all extracted features\n",
    "        model: Trained model\n",
    "        feature_names: List of feature names\n",
    "    \n",
    "    Returns:\n",
    "        Score (probability)\n",
    "    \"\"\"\n",
    "    features = [ipo_info.get(f, 0) for f in feature_names]\n",
    "    features_array = np.array(features).reshape(1, -1)\n",
    "    score = model.predict_proba(features_array)[0][1]\n",
    "    return score\n",
    "\n",
    "# Example upcoming IPO\n",
    "upcoming_ipo = {\n",
    "    'ticker': 'NEWCO',\n",
    "    'listing_date': '2025-01-15',\n",
    "    'revenue_mm': 800,\n",
    "    'revenue_growth_yoy': 65,\n",
    "    'gross_margin': 72,\n",
    "    'operating_margin': -12,\n",
    "    'is_profitable': 0,\n",
    "    'cash_mm': 200,\n",
    "    'debt_to_equity': 0.3,\n",
    "    'customer_concentration': 18,\n",
    "    'employees': 2500,\n",
    "    'company_age': 7,\n",
    "    'price_vs_range': 12,  # Priced above range (good sign)\n",
    "    'float_pct': 18,\n",
    "    'price_to_sales': 8.5,\n",
    "    'underwriter_tier': 1,  # Goldman Sachs\n",
    "    'lockup_days': 180,\n",
    "    'greenshoe_pct': 15,\n",
    "    'proceeds_for_growth': 0.8,\n",
    "    'subscription_level': 1.2,\n",
    "    'vix': 14,  # Low volatility\n",
    "    'spy_return_30d': 3.5,  # Strong market\n",
    "    'sector_return_30d': 5.2,\n",
    "    'ipo_market_temp': 12,  # Hot IPO market\n",
    "    'ipos_same_week': 2,\n",
    "    'finbert_score': 0.45,  # Positive sentiment\n",
    "    'news_volume': 28,\n",
    "    'sentiment_velocity': 0.3,\n",
    "    'social_buzz': 65,\n",
    "    'google_trends': 78\n",
    "}\n",
    "\n",
    "score = score_new_ipo(upcoming_ipo, model, feature_names)\n",
    "print(f\"\\nIPO Score for {upcoming_ipo['ticker']}: {score:.3f}\")\n",
    "print(f\"Trade Recommendation: {'BUY' if score > 0.70 else 'PASS'}\")\n",
    "\n",
    "if score > 0.70:\n",
    "    print(f\"Expected probability of >10% return in 30 days: {score:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export upcoming IPOs to CSV for trading algorithm\n",
    "# This is what the algorithm will read\n",
    "\n",
    "upcoming_ipos = [\n",
    "    {\n",
    "        'date': '2025-01-15',\n",
    "        'ticker': 'NEWCO',\n",
    "        'company_name': 'New Company Inc',\n",
    "        'score': score,\n",
    "        'offer_price': 25.00,\n",
    "        'shares_offered': 15000000,\n",
    "        'sector': 'Technology'\n",
    "    },\n",
    "    # Add more IPOs here as you score them\n",
    "]\n",
    "\n",
    "ipo_calendar_df = pd.DataFrame(upcoming_ipos)\n",
    "\n",
    "# Save to Object Store for algorithm to use\n",
    "ipo_calendar_csv = ipo_calendar_df.to_csv(index=False)\n",
    "qb.object_store.save('ipo_calendar', ipo_calendar_csv)\n",
    "\n",
    "print(\"\\nIPO calendar exported to Object Store!\")\n",
    "print(ipo_calendar_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "1. ✅ Model trained and saved\n",
    "2. ✅ Upcoming IPOs scored\n",
    "3. ✅ Scores exported to Object Store\n",
    "4. → Deploy `main.py` algorithm to QuantConnect\n",
    "5. → Monitor trades and performance\n",
    "6. → Retrain model quarterly with new data\n",
    "\n",
    "**Weekly Workflow:**\n",
    "- Monday: Check IPO calendar for upcoming listings\n",
    "- Tuesday: Download S-1 filings, extract features\n",
    "- Wednesday: Score IPOs, update calendar CSV\n",
    "- Thursday: Upload to Object Store\n",
    "- Friday: Algorithm ready to trade next week's IPOs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
